{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr3pZCd6k5XT0ZZ5t7Myz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52144/ExplainableAI_Assignment/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Car Evaluation using Decision Tree & LIME**\n",
        "\n",
        "**Introduction:**\n",
        "This report focuses on predicting car acceptability based on categorical automotive attributes using a Decision Tree Classifier.\n",
        "The objective is twofold:\n",
        "1.\tTrain a Decision Tree model on the Car Evaluation dataset.\n",
        "2.\tApply LIME (Local Interpretable Model-agnostic Explanations) to interpret feature contributions for specific predictions.\n",
        "Dataset Description:\n",
        "Source: UCI Car Evaluation Dataset\n",
        "Size:\n",
        "•\tSamples: 1728 cars\n",
        "•\tFeatures: 6 categorical features\n",
        "Features:\n",
        "•\tBuying\n",
        "•\tMaintenance (maint)\n",
        "•\tDoors\n",
        "•\tPersons (capacity)\n",
        "•\tLuggage Boot Size (lug_boot)\n",
        "•\tSafety\n",
        "Target Variable:\n",
        "•\tClass (unacc, acc, good, vgood)\n",
        "\n",
        "**Preprocessing Steps:**\n",
        "\n",
        "Categorical Encoding:\n",
        "\n",
        "Applied Label Encoding to all categorical features.\n",
        "Data Splitting: 80% training and 20% testing using train_test_split(random_state=42).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Model & Performance:**\n",
        "\n",
        "Algorithm: Decision Tree Classifier\n",
        "Parameters: Default (random_state=42)\n",
        "Classification Report\n",
        "               precision     recall     f1-score     support\n",
        "\n",
        "           0       0.97         0.92          0.94             83\n",
        "           1       0.62         0.91          0.74             11\n",
        "           2       1.00         1.00         1.00             235\n",
        "           3       1.00         0.94          0.97             17\n",
        "\n",
        "    accuracy                                       0.97        346\n",
        "\n",
        "   macro avg         0.90      0.94      0.91        346\n",
        "\n",
        "  weighted avg       0.98      0.97      0.98       346\n",
        "\n",
        "Accuracy: 97%\n",
        "\n",
        "Class 2 (unacc/acc depending on encoding) predicted perfectly.\n",
        "     \n",
        "Class 1 had slightly lower precision (0.62).\n",
        "\n",
        "**LIME Analysis:**\n",
        "Instance Explained: Test sample #5\n",
        "Predicted Class: acc\n",
        "Feature Contributions\n",
        "maint=vhigh   → -0.0678\n",
        "safety=med    → +0.0507\n",
        "persons=4     → +0.0496\n",
        "buying=med    → +0.0263\n",
        "lug_boot=med  → +0.0207\n",
        "doors=4       → +0.0116\n",
        "\n",
        "\n",
        "\n",
        "**Interpretation**\n",
        "\n",
        "•\tPositive Influences: Medium safety, seating for 4 persons, and medium luggage space increased the likelihood of the car being classified as \"acceptable.\"\n",
        "\n",
        "**Negative Influence:**\n",
        "\n",
        "High maintenance cost (maint=vhigh) reduced the probability of acceptance.\n",
        "•\tOther features contributed slightly positively.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The Decision Tree achieved 97% accuracy on the test data.\n",
        "LIME explanations provided clear, local insights into the model’s reasoning.\n",
        "\n",
        "**Key Takeaway:**\n",
        "\n",
        "Safety and passenger capacity are strong indicators for car acceptability, while high maintenance costs discourage acceptability.\n"
      ],
      "metadata": {
        "id": "4fBQ9oZ9M5_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnzPcNMt6IZz",
        "outputId": "785f83de-d32c-4a29-88d7-0941e90c14bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94        83\n",
            "           1       0.62      0.91      0.74        11\n",
            "           2       1.00      1.00      1.00       235\n",
            "           3       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.97       346\n",
            "   macro avg       0.90      0.94      0.91       346\n",
            "weighted avg       0.98      0.97      0.98       346\n",
            "\n",
            "\n",
            " LIME Explanation for test instance #5:\n",
            "Predicted class: acc\n",
            "Feature contributions:\n",
            "maint=vhigh: -0.0626\n",
            "safety=med: 0.0441\n",
            "persons=4: 0.0309\n",
            "buying=med: 0.0282\n",
            "lug_boot=med: 0.0111\n",
            "doors=4: 0.0008\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import lime\n",
        "except ModuleNotFoundError:\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install -q lime\n",
        "    import lime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import lime.lime_tabular\n",
        "\n",
        "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "df = pd.read_csv('car.data', names=columns)\n",
        "\n",
        "label_encoders = {}\n",
        "for col in df.columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\" Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "categorical_names = {i: label_encoders[col].classes_ for i, col in enumerate(X.columns)}\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train.values,\n",
        "    feature_names=X.columns.tolist(),\n",
        "    class_names=label_encoders['class'].classes_,\n",
        "    categorical_features=list(range(X.shape[1])),\n",
        "    categorical_names=categorical_names,\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "i = 5\n",
        "instance = X_test.values[i]\n",
        "\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=instance,\n",
        "    predict_fn=clf.predict_proba,\n",
        "    num_features=6\n",
        ")\n",
        "\n",
        "print(\"\\n LIME Explanation for test instance #5:\")\n",
        "predicted_class = clf.predict([instance])[0]\n",
        "decoded_class = label_encoders['class'].inverse_transform([predicted_class])[0]\n",
        "print(f\"Predicted class: {decoded_class}\")\n",
        "print(\"Feature contributions:\")\n",
        "for feature, weight in exp.as_list():\n",
        "    print(f\"{feature}: {weight:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mushroom Classification using Random Forest & LIME**\n",
        "**Introduction:**\n",
        "\n",
        "\n",
        "This project focuses on predicting whether a mushroom is edible or poisonous based on its physical and categorical attributes. The Mushroom dataset from the UCI Machine Learning Repository was used.\n",
        "The goal of this study is twofold:\n",
        "\n",
        "Train a Random Forest Classifier to distinguish between edible and poisonous mushrooms.\n",
        "\n",
        "\n",
        "Apply LIME (Local Interpretable Model-agnostic Explanations) to interpret the feature contributions behind individual predictions.\n",
        "Dataset Description:\n",
        "   \n",
        "**Source:**\n",
        "\n",
        "UCI Machine Learning Repository – Agaricus and Lepiota Mushroom dataset\n",
        "  \n",
        "  \n",
        "  Samples: ~8,124 mushrooms\n",
        "  \n",
        "  \n",
        "  Features: 22 categorical attributes\n",
        "  \n",
        "  Target Variable:\n",
        "•\tclass: edible (e) or poisonous (p)\n",
        "\n",
        "**Tasks**\n",
        "1.\tLoad dataset\n",
        "2.\tTrain Random Forest\n",
        "3.\tApply LIME\n",
        "4.\tInterpret results\n",
        "\n",
        "**Preprocessing Steps**\n",
        "\n",
        "•\tCategorical Encoding: Applied Label Encoding to convert features into numeric form.\n",
        "\n",
        "•\tData Splitting: 80% training and 20% testing (train_test_split(random_state=42)).\n",
        "\n",
        "**Model & Performance**\n",
        "\n",
        "Algorithm: Random Forest Classifier\n",
        "\n",
        "•\tParameters:\n",
        "\n",
        "n_estimators=100\n",
        "\n",
        "random_state=42\n",
        "\n",
        "**Classification Report**\n",
        "\n",
        "Class\t     Precision\t   Recall\t   F1-Score\t  Support\n",
        "\n",
        "0 (Edible)\t1.00\t  1.00\t  1.00\t  843\n",
        "\n",
        "1 (Poisonous)\t1.00\t  1.00\t  1.00\t  782\n",
        "\n",
        "\n",
        "Accuracy: 1.00\n",
        "\n",
        "Macro Avg F1: 1.00\n",
        "\n",
        "Weighted Avg F1: 1.00\n",
        "\n",
        "The Random Forest model achieved perfect accuracy (100%), showing the dataset is highly separable based on features like odor, gill properties, and stalk surface.\n",
        "\n",
        "\n",
        "**LIME Analysis**\n",
        "\n",
        "Instance Explained: Test sample #5\n",
        "\n",
        "Predicted Class: poisonous\n",
        "\n",
        "Feature Contributions:\n",
        "\n",
        "odor=y → +0.1129\n",
        "\n",
        "gill-color=b → +0.1062\n",
        "\n",
        "gill-size=n → +0.1044\n",
        "\n",
        "stalk-surface-above-ring=k → +0.0873\n",
        "\n",
        "gill-spacing=c → +0.0584\n",
        "\n",
        " bruises=f → +0.0468\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "•\tThe odor (y = foul smell) is the strongest indicator for poisonous classification.\n",
        "\n",
        "•\tOther features like gill color and gill size also contribute positively towards predicting \"poisonous\".\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "•\tKey Insights:\n",
        "\n",
        "The Mushroom dataset is highly predictable with Random Forest achieving 100% accuracy.\n",
        "\n",
        "LIME explanations reveal that features like odor, gill size, and gill color are critical in identifying poisonous mushrooms.\n",
        "\n",
        "**•\tLimitations:**\n",
        "\n",
        "The dataset is entirely categorical, so real-world continuous measurements are missing.\n",
        "\n",
        "Model might not generalize if unseen mushroom species are introduced.\n",
        "\n",
        "**•\tImprovements:**\n",
        "\n",
        "Compare with other interpretable models like Decision Trees.\n",
        "\n",
        "Experiment with SHAP for global + local interpretability.\n",
        "\n",
        "Validate with real-world mushroom identification cases.\n"
      ],
      "metadata": {
        "id": "IqovUTA0NgPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import lime\n",
        "except ModuleNotFoundError:\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install -q lime\n",
        "    import lime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import lime.lime_tabular\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
        "columns = [\n",
        "    'class','cap-shape','cap-surface','cap-color','bruises','odor',\n",
        "    'gill-attachment','gill-spacing','gill-size','gill-color',\n",
        "    'stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring',\n",
        "    'stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color',\n",
        "    'ring-number','ring-type','spore-print-color','population','habitat'\n",
        "]\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoders = {}\n",
        "for col in df.columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Random Forest\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\" Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# LIME Explanation\n",
        "categorical_names = {i: label_encoders[col].classes_ for i, col in enumerate(X.columns)}\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train.values,\n",
        "    feature_names=X.columns.tolist(),\n",
        "    class_names=label_encoders['class'].classes_,\n",
        "    categorical_features=list(range(X.shape[1])),\n",
        "    categorical_names=categorical_names,\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "i = 5\n",
        "instance = X_test.values[i]\n",
        "\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=instance,\n",
        "    predict_fn=clf.predict_proba,\n",
        "    num_features=6\n",
        ")\n",
        "\n",
        "print(\"\\n LIME Explanation for test instance #5:\")\n",
        "predicted_class = clf.predict([instance])[0]\n",
        "decoded_class = label_encoders['class'].inverse_transform([predicted_class])[0]\n",
        "print(f\"Predicted class: {decoded_class}\")\n",
        "print(\"Feature contributions:\")\n",
        "for feature, weight in exp.as_list():\n",
        "    print(f\"{feature}: {weight:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnWXg0uEKlXs",
        "outputId": "0ee8b928-3cd8-4c08-9145-cae6eda72ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n",
            "\n",
            " LIME Explanation for test instance #5:\n",
            "Predicted class: p\n",
            "Feature contributions:\n",
            "odor=y: 0.1129\n",
            "gill-color=b: 0.1062\n",
            "gill-size=n: 0.1044\n",
            "stalk-surface-above-ring=k: 0.0873\n",
            "gill-spacing=c: 0.0584\n",
            "bruises=f: 0.0468\n"
          ]
        }
      ]
    }
  ]
}